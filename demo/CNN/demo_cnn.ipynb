{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import dlib\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, hid_1, hid_2, hid_3, hid_4, hid_5, hid_6, x, y, drop_1, drop_2, out):\n",
    "        super().__init__()\n",
    "\n",
    "        # First block\n",
    "        self.conv1 = nn.Conv2d(3, hid_1, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hid_1)\n",
    "        self.conv2 = nn.Conv2d(hid_1, hid_2, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hid_2)\n",
    "\n",
    "        # Second block\n",
    "        self.conv3 = nn.Conv2d(hid_2, hid_3, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(hid_3)\n",
    "        self.conv4 = nn.Conv2d(hid_3, hid_4, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(hid_4)\n",
    "\n",
    "        # Third bLock\n",
    "        self.conv5 = nn.Conv2d(hid_4, hid_5, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(hid_5)\n",
    "        self.conv6 = nn.Conv2d(hid_5, hid_6, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(hid_6)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(hid_6 * x * y, 512)\n",
    "        self.bn7 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, out)\n",
    "\n",
    "        # MaxPooling, Dropout2d, Dropout Fully Connected\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.dropout2d = nn.Dropout2d(drop_1)\n",
    "        self.dropout = nn.Dropout(drop_2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First block\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Second block\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "\n",
    "        # Third bLock\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Dropout e Flatten\n",
    "        x = self.dropout2d(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten\n",
    "\n",
    "        # Fully connected\n",
    "        x = F.relu(self.bn7(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)  # Output layer\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shape_predictor_path = \"//Users/valentinaemili/Desktop/biometric_systems_project/shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector() # HOG-based detector\n",
    "predictor = dlib.shape_predictor(shape_predictor_path)\n",
    "\n",
    "def shape_to_normal(shape):\n",
    "  shape_normal = []\n",
    "  for i in range(0, shape.num_parts):\n",
    "    shape_normal.append((i, (shape.part(i).x, shape.part(i).y)))\n",
    "  return shape_normal\n",
    "\n",
    "def get_eyes_nose_dlib(shape):\n",
    "  nose = shape[30][1]\n",
    "  left_eye_x = (shape[36][1][0] + shape[39][1][0]) // 2\n",
    "  left_eye_y = (shape[36][1][1] + shape[39][1][1]) // 2\n",
    "  right_eyes_x = (shape[42][1][0] + shape[45][1][0]) // 2\n",
    "  right_eyes_y = (shape[42][1][1] + shape[45][1][1]) // 2\n",
    "\n",
    "  return nose, (left_eye_x, left_eye_y), (right_eyes_x, right_eyes_y)\n",
    "\n",
    "def rotate_points(shape, rotation_matrix):\n",
    "  points = []\n",
    "  for i in range(0, 68):\n",
    "    x,y = shape[i][1]\n",
    "    points.append((x, y, 1))\n",
    "  points = np.array(points)\n",
    "  rotated_points = np.dot(rotation_matrix, points.T).T\n",
    "  return np.array([(int(p[0]), int(p[1])) for p in rotated_points])\n",
    "\n",
    "def get_eyes_in_image(image, points):\n",
    "  height, width = image.shape[:2]\n",
    "  top = points[17:27][np.argmin(points[17:27, 1])]\n",
    "  bottom = points[29]\n",
    "  min_x, min_y = np.min(points[36:48, 0]), np.min(points[36:48, 1])\n",
    "  max_x, max_y = np.max(points[36:48, 0]), np.max(points[36:48, 1])\n",
    "  min_x, min_y = max(0, min_x - 10), max(top[1], min_y - 10)\n",
    "  max_x, max_y = min(width, max_x + 10), min(bottom[1], max_y + 10)\n",
    "  image = image[min_y:max_y, min_x:max_x]\n",
    "  return image\n",
    "\n",
    "def get_nose_in_image(image, points):\n",
    "  height, width = image.shape[:2]\n",
    "  top = points[36:48][np.argmin(points[36:48, 1])]\n",
    "  bottom = points[48:68][np.argmax(points[48:68, 1])]\n",
    "  min_x, min_y = np.min(points[27:36, 0]), np.min(points[27:36, 1])\n",
    "  max_x, max_y = np.max(points[27:36, 0]), np.max(points[27:36, 1])\n",
    "  min_x, min_y = max(0, min_x - 5), max(top[1], min_y - 5)\n",
    "  max_x, max_y = min(width, max_x + 5), min(bottom[1], max_y + 5)\n",
    "  image = image[min_y:max_y, min_x:max_x]\n",
    "  return image\n",
    "\n",
    "def get_mouth_in_image(image, points):\n",
    "  height, width = image.shape[:2]\n",
    "  top = points[27:36][np.argmin(points[27:36, 1])]\n",
    "  min_x, min_y = np.min(points[48:68, 0]), np.min(points[48:68, 1])\n",
    "  max_x, max_y = np.max(points[48:68, 0]), np.max(points[48:68, 1])\n",
    "  min_x, min_y = max(0, min_x - 10), max(top[1], min_y - 10)\n",
    "  max_x, max_y = min(width, max_x + 10), min(height, max_y + 10)\n",
    "  image = image[min_y:max_y, min_x:max_x]\n",
    "  return image\n",
    "\n",
    "def align_face(image):\n",
    "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  faces = detector(gray)\n",
    "  if len(faces) > 0:\n",
    "    for face in faces:\n",
    "      shape = predictor(gray, face)\n",
    "      shape = shape_to_normal(shape)\n",
    "      nose, left_eye, right_eye = get_eyes_nose_dlib(shape)\n",
    "      delta_x = right_eye[0] - left_eye[0]\n",
    "      delta_y = right_eye[1] - left_eye[1]\n",
    "      angle = math.atan2(delta_y, delta_x) * (180 / math.pi)\n",
    "      center_of_eyes = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)\n",
    "      rotation_matrix = cv2.getRotationMatrix2D(center_of_eyes, angle, scale=1.0)\n",
    "      h, w = image.shape[:2]\n",
    "      aligned_image = cv2.warpAffine(image, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR)\n",
    "      rotated_points = rotate_points(shape, rotation_matrix)\n",
    "      eyes_image = get_eyes_in_image(aligned_image, rotated_points)\n",
    "      nose_image = get_nose_in_image(aligned_image, rotated_points)\n",
    "      mouth_image = get_mouth_in_image(aligned_image, rotated_points)\n",
    "      return (eyes_image, nose_image, mouth_image)\n",
    "  return (False, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model pre-trained on ImageNet dataset\n",
    "transform_eyes = transforms.Compose([\n",
    "    transforms.Resize((44, 266)),  # Cambia dimensione a (altezza, larghezza)\n",
    "    transforms.ToTensor(),        # Converte l'immagine in tensor\n",
    "    transforms.Normalize(mean = [0.56551169, 0.4201522,  0.35519068], std = [0.22746577, 0.20109357, 0.19388984])\n",
    "])\n",
    "\n",
    "# Transform per il naso (108x170)\n",
    "transform_nose = transforms.Compose([\n",
    "    transforms.Resize((170, 108)),  # Cambia dimensione a (altezza, larghezza)\n",
    "    transforms.ToTensor(),         # Converte l'immagine in tensor\n",
    "    transforms.Normalize(mean = [0.70585869, 0.5230923,  0.44163547], std = [0.19556989, 0.19164655, 0.19488743])\n",
    "])\n",
    "\n",
    "# Transform per la bocca (193x89)\n",
    "transform_mouth = transforms.Compose([\n",
    "    transforms.Resize((89, 193)),  # Cambia dimensione a (altezza, larghezza)\n",
    "    transforms.ToTensor(),        # Converte l'immagine in tensor\n",
    "    transforms.Normalize(mean = [0.64867712, 0.4592991,  0.39606173], std = [0.2005014,  0.18597975, 0.18335514])\n",
    "])\n",
    "\n",
    "e_x = 16\n",
    "e_y = 2\n",
    "n_x = 6\n",
    "n_y = 10\n",
    "m_x = 12\n",
    "m_y = 5\n",
    "\n",
    "hid_1 = 64\n",
    "hid_2 = 64\n",
    "hid_3 = 128\n",
    "hid_4 = 128\n",
    "hid_5 = 128\n",
    "hid_6 = 128\n",
    "drop_1 = 0.2\n",
    "drop_2 = 0.5\n",
    "\n",
    "out_age = 8\n",
    "out_gender = 2\n",
    "out_ethnicity = 5\n",
    "\n",
    "eyes_gender = CNN(hid_1, hid_2, hid_3, hid_4, hid_5, hid_6, e_x, e_y, drop_1, drop_2,out_gender)\n",
    "eyes_age = CNN(hid_1, hid_2, hid_3, hid_4, hid_5, hid_6, e_x, e_y, drop_1, drop_2,out_age)\n",
    "eyes_ethnicity = CNN(hid_1, hid_2, hid_3, hid_4, hid_5, hid_6, e_x, e_y, drop_1, drop_2,out_ethnicity)\n",
    "nose_gender = CNN(hid_1, hid_2, hid_3, hid_4, hid_5, hid_6, n_x, n_y, drop_1, drop_2,out_gender)\n",
    "nose_age = CNN(hid_1, hid_2, hid_3, hid_4, hid_5, hid_6, n_x, n_y, drop_1, drop_2,out_age)\n",
    "nose_ethnicity = CNN(hid_1, hid_2, hid_3, hid_4, hid_5, hid_6, n_x, n_y, drop_1, drop_2,out_ethnicity)\n",
    "mouth_gender = CNN(hid_1, hid_2, hid_3, hid_4, hid_5, hid_6, m_x, m_y, drop_1, drop_2,out_gender) \n",
    "mouth_age = CNN(hid_1, hid_2, hid_3, hid_4, hid_5, hid_6, m_x, m_y, drop_1, drop_2, out_age) \n",
    "mouth_ethnicity = CNN(hid_1, hid_2, hid_3, hid_4, hid_5, hid_6, m_x, m_y, drop_1, drop_2,out_ethnicity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  folder_path = \"/Users/valentinaemili/Desktop/biometric_systems_project/trained_model\"\n",
    "  characteristics = [\"age\",\"gender\",\"ethnicity\"]\n",
    "  features = [\"eyes\", \"mouth\", \"nose\"]\n",
    "  ages = [\"around 3 yrs\", \"around 9 yrs\", \"around 17 yrs\", \"around 28 yrs\", \"around 43 yrs\", \"around 63 yrs\", \"around 83 yrs\", \"around 104 yrs\"]\n",
    "  ethnicities = [\"White\", \"Black\", \"Asian\", \"Indian\", \"Hispanic/Latino/Middle Eastern\"]\n",
    "  gender = [\"male\", \"female\"]\n",
    "  models = {}\n",
    "  for c in characteristics:\n",
    "    for feature in features:\n",
    "      feature_path = os.path.join(folder_path, c, f\"best_{feature}_{c}.pth\")\n",
    "      if feature == \"eyes\":\n",
    "        if c == \"age\":\n",
    "          model = eyes_age\n",
    "        elif c == \"gender\":\n",
    "          model = eyes_gender\n",
    "        else:\n",
    "          model = eyes_ethnicity\n",
    "      elif feature == \"mouth\":\n",
    "        if c == \"age\":\n",
    "          model = mouth_age\n",
    "        elif c == \"gender\":\n",
    "          model = mouth_gender\n",
    "        else:\n",
    "          model = mouth_ethnicity\n",
    "      else:\n",
    "        if c == \"age\":\n",
    "          model = nose_age\n",
    "        elif c == \"gender\":\n",
    "          model = nose_gender\n",
    "        else:\n",
    "          model = nose_ethnicity\n",
    "      model.load_state_dict(torch.load(feature_path, map_location=torch.device('cpu')))\n",
    "      models[(c, feature)] = model\n",
    "\n",
    "  cap = cv2.VideoCapture(0)\n",
    "  while True:\n",
    "    ret, img = cap.read() # ret is bool\n",
    "    if ret:\n",
    "      img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "      eyes, nose, mouth = align_face(img_rgb)\n",
    "      if eyes is not False:\n",
    "        eyes = transform_eyes(Image.fromarray(eyes)).unsqueeze(0) # Add batch dimension\n",
    "\n",
    "        nose = transform_nose(Image.fromarray(nose)).unsqueeze(0) # Add batch dimension\n",
    "\n",
    "        mouth = transform_mouth(Image.fromarray(mouth)).unsqueeze(0) # Add batch dimension\n",
    "        predictions_text = \"\"\n",
    "        for c in characteristics:\n",
    "          for feature in features:\n",
    "            model = models[(c, feature)]\n",
    "            model.eval()\n",
    "            if feature == \"eyes\":\n",
    "              y_pred = model(eyes)\n",
    "            elif feature == \"mouth\":\n",
    "              y_pred = model(mouth)\n",
    "            else:\n",
    "              y_pred = model(nose)\n",
    "            predicted_class = torch.argmax(y_pred, dim=1).item()  # Get the index of the highest value\n",
    "            if c == \"age\":\n",
    "              predictions_text += f\"{feature} ({c}): {ages[predicted_class]}\\n\"\n",
    "            elif c == \"ethnicity\":\n",
    "              predictions_text += f\"{feature} ({c}): {ethnicities[predicted_class]}\\n\"\n",
    "            else:\n",
    "              predictions_text += f\"{feature} ({c}): {gender[predicted_class]}\\n\"\n",
    "        y_offset = 30  # Start drawing the text at the y-coordinate\n",
    "        for line in predictions_text.splitlines():\n",
    "          cv2.putText(img, line, (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "          y_offset += 30  # Move down to draw the next line\n",
    "        cv2.imshow('Video Frame with Predictions', img)\n",
    "        k = cv2.waitKey(3)\n",
    "        if k == ord('q'):\n",
    "          break\n",
    "  cap.release()\n",
    "  cv2.destroyAllWindows()\n",
    "  cv2.waitKey(1)\n",
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
