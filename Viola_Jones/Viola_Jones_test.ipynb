{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gPZw9SuImUg"
      },
      "outputs": [],
      "source": [
        "%pip install gdown\n",
        "import gdown\n",
        "\n",
        "url = \"https://drive.google.com/drive/folders/1_z2a2W9ZmOhjz9FeNhn5GftGC-G-31N9?usp=sharing\"\n",
        "gdown.download_folder(url, quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "SN4t2u8xMGkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm\n",
        "\n",
        "def main():\n",
        "  def update_dictionary(key, dictionary, file_name):\n",
        "    if key not in dictionary:\n",
        "      dictionary[key] = {file_name}\n",
        "    else:\n",
        "      dictionary[key].add(file_name)\n",
        "\n",
        "  # folder containing the zip files and the one that will contains the images extracted from those files\n",
        "  folder_path = \"/content/biometric_systems_project\"\n",
        "  for file_name in os.listdir(folder_path):\n",
        "\n",
        "    # zipped files in the folder biometric_systems_dataset\n",
        "    if file_name.endswith(\".zip\"):\n",
        "\n",
        "      # full path to the zip file\n",
        "      file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "      # create folder in the same path with the name of the zip file\n",
        "      extract_folder = os.path.join(folder_path, file_name.replace(\".zip\", \"\"))\n",
        "      os.makedirs(extract_folder, exist_ok=True)\n",
        "\n",
        "      # open and extract the file\n",
        "      with zipfile.ZipFile(file_path, mode=\"r\") as zip_ref:\n",
        "        zip_ref.extractall(extract_folder)\n",
        "\n",
        "        for root, _, files in os.walk(extract_folder):\n",
        "          for image_file in files:\n",
        "            if image_file.lower().endswith('.jpg'):\n",
        "              source_file = os.path.join(root, image_file)\n",
        "              destination_file = os.path.join(folder_path, image_file)\n",
        "\n",
        "              # move the image file to the destination path\n",
        "              shutil.move(source_file, destination_file)\n",
        "\n",
        "        # remove the extracted folder and all its contents\n",
        "        shutil.rmtree(extract_folder)\n",
        "        os.remove(extract_folder + \".zip\")\n",
        "\n",
        "  ages, genders, ethnicities = dict(), dict(), dict()\n",
        "  for file_name in os.listdir(folder_path):\n",
        "\n",
        "    # rename pictures that start with \"._\"\n",
        "    if(file_name[0] != \"h\"):\n",
        "      if (file_name[0] == \".\"):\n",
        "        file_name = file_name[2:]\n",
        "      else:\n",
        "        age, gender, ethnicity, _ = file_name.split(\"_\")\n",
        "        update_dictionary(age, ages, file_name)\n",
        "        update_dictionary(gender, genders, file_name)\n",
        "        update_dictionary(ethnicity, ethnicities, file_name)\n",
        "\n",
        "  face_cascade_path = \"/content/biometric_systems_project/haarcascade_frontalface_default.xml\"\n",
        "  eye_cascade_path = \"/content/biometric_systems_project/haarcascade_eye.xml\"\n",
        "  nose_cascade_path = \"/content/biometric_systems_project/haarcascade_mcs_nose.xml\"\n",
        "  mouth_cascade_path = \"/content/biometric_systems_project/haarcascade_mcs_mouth.xml\"\n",
        "\n",
        "  face_cascade = cv2.CascadeClassifier(face_cascade_path)\n",
        "  eye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n",
        "  nose_cascade = cv2.CascadeClassifier(nose_cascade_path)\n",
        "  mouth_cascade = cv2.CascadeClassifier(mouth_cascade_path)\n",
        "\n",
        "  # Controlla se ciascun file di cascata è stato caricato correttamente\n",
        "  if face_cascade.empty():\n",
        "      print(\"Errore: il file haarcascade_frontalface_default.xml non è stato trovato o caricato correttamente.\")\n",
        "      return\n",
        "  if eye_cascade.empty():\n",
        "      print(\"Errore: il file haarcascade_eye.xml non è stato trovato o caricato correttamente.\")\n",
        "      return\n",
        "  if nose_cascade.empty():\n",
        "      print(\"Errore: il file haarcascade_mcs_nose.xml non è stato trovato o caricato correttamente.\")\n",
        "      return\n",
        "  if mouth_cascade.empty():\n",
        "      print(\"Errore: il file haarcascade_mcs_mouth.xml non è stato trovato o caricato correttamente.\")\n",
        "      return\n",
        "  EYES, MOUTH, NOSE = 0, 0, 0\n",
        "  total_images = len([name for name in os.listdir(folder_path) if name.lower().endswith('.jpg')])\n",
        "\n",
        "  # ciclo for che mostra la barra di progresso\n",
        "  for file_name in tqdm(os.listdir(folder_path), desc=\"Elaborating images\", total=total_images):\n",
        "  #for file_name in os.listdir(folder_path):\n",
        "    image_path = os.path.join(folder_path, file_name)\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is None:\n",
        "        continue  # Salta se l'immagine non può essere letta\n",
        "    count_eyes, count_nose, count_mouth = 0, 0, 0\n",
        "    # Converti l'immagine in scala di grigi\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    # Seleziona il primo volto trovato\n",
        "    for (x, y, w, h) in faces:\n",
        "      face_roi = gray_image[y:y+h, x:x+w]\n",
        "\n",
        "      # Rilevamento degli occhi\n",
        "      eyes = eye_cascade.detectMultiScale(face_roi)\n",
        "      for (ex, ey, ew, eh) in eyes:\n",
        "          cv2.rectangle(image, (x+ex, y+ey), (x+ex+ew, y+ey+eh), (0, 255, 0), 2)\n",
        "          count_eyes +=1\n",
        "      # Rilevamento del naso\n",
        "      noses = nose_cascade.detectMultiScale(face_roi, scaleFactor=1.1, minNeighbors=5)\n",
        "      for (nx, ny, nw, nh) in noses:\n",
        "          cv2.rectangle(image, (x+nx, y+ny), (x+nx+nw, y+ny+nh), (255, 0, 0), 2)\n",
        "          count_nose +=1\n",
        "      # Rilevamento della bocca\n",
        "      mouths = mouth_cascade.detectMultiScale(face_roi, scaleFactor=1.1, minNeighbors=5)\n",
        "      for (mx, my, mw, mh) in mouths:\n",
        "          # Filtra per le bocche in basso nel volto (approssimazione)\n",
        "          if my > h // 2:\n",
        "              cv2.rectangle(image, (x+mx, y+my), (x+mx+mw, y+my+mh), (0, 0, 255), 2)\n",
        "              count_mouth +=1\n",
        "\n",
        "      if (1<= count_eyes <= 2):\n",
        "        EYES += 1\n",
        "      if (count_nose == 1):\n",
        "        NOSE += 1\n",
        "      if (count_mouth == 1):\n",
        "        MOUTH += 1\n",
        "      #cv2_imshow(image)  # Usa cv2_imshow per Colab\n",
        "      #cv2.waitKey(500)\n",
        "\n",
        "  print(\"EYES: \", EYES)\n",
        "  print(\"NOSE: \", NOSE)\n",
        "  print(\"MOUTH: \", MOUTH)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "VVUgPSZhIssm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}