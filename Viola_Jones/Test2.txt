%pip install gdown
!pip install tqdm
import gdown

#url = "https://drive.google.com/drive/folders/1_z2a2W9ZmOhjz9FeNhn5GftGC-G-31N9?usp=sharing"
url = "https://drive.google.com/drive/folders/1Fl3JRqZrW4n-FOjstaIJmu02FkkNgpkw?usp=sharing"
gdown.download_folder(url, quiet=True)

import zipfile
import os
import cv2
import shutil
import numpy as np
from google.colab.patches import cv2_imshow
from tqdm import tqdm

def main():
  def update_dictionary(key, dictionary, file_name):
    if key not in dictionary:
      dictionary[key] = {file_name}
    else:
      dictionary[key].add(file_name)

  # folder containing the zip files and the one that will contains the images extracted from those files
  folder_path = "/content/VGGFaces2"
  for file_name in os.listdir(folder_path):

    # zipped files in the folder biometric_systems_dataset
    if file_name.endswith(".zip"):

      # full path to the zip file
      file_path = os.path.join(folder_path, file_name)

      # create folder in the same path with the name of the zip file
      extract_folder = os.path.join(folder_path, file_name.replace(".zip", ""))
      os.makedirs(extract_folder, exist_ok=True)

      # open and extract the file
      count = 0
      with zipfile.ZipFile(file_path, mode="r") as zip_ref:
        zip_ref.extractall(extract_folder)

        for root, _, files in os.walk(extract_folder):
          for image_file in files:
            if image_file.lower().endswith('.jpg'):
              count += 1
              source_file = os.path.join(root, image_file)
              new_image_name = f"{count}_{image_file}"
              destination_file = os.path.join(folder_path, new_image_name)


              # move the image file to the destination path
              shutil.move(source_file, destination_file)

        # remove the extracted folder and all its contents
        shutil.rmtree(extract_folder)
        os.remove(extract_folder + ".zip")

  # ages, genders, ethnicities = dict(), dict(), dict()
  # for file_name in os.listdir(folder_path):

  #   # rename pictures that start with "._"
  #   if(file_name[0] != "h"):
  #     if (file_name[0] == "."):
  #       file_name = file_name[2:]
  #     else:
  #       age, gender, ethnicity, _ = file_name.split("_")
  #       update_dictionary(age, ages, file_name)
  #       update_dictionary(gender, genders, file_name)
  #       update_dictionary(ethnicity, ethnicities, file_name)

  face_cascade_path = "/content/VGGFaces2/haarcascade_frontalface_default.xml"

  face_cascade = cv2.CascadeClassifier(face_cascade_path)

  # Controlla se ciascun file di cascata è stato caricato correttamente
  if face_cascade.empty():
      print("Errore: il file haarcascade_frontalface_default.xml non è stato trovato o caricato correttamente.")
      return
  total_images = len([name for name in os.listdir(folder_path) if name.lower().endswith('.jpg')])
  Face = 0
  # ciclo for che mostra la barra di progresso
  for file_name in tqdm(os.listdir(folder_path), desc="Elaborating images", total=total_images):
  #for file_name in os.listdir(folder_path):
    image_path = os.path.join(folder_path, file_name)
    image = cv2.imread(image_path)

    if image is None:
        continue  # Salta se l'immagine non può essere letta
    count_eyes, count_nose, count_mouth = 0, 0, 0
    # Converti l'immagine in scala di grigi
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.05, minNeighbors=3, minSize=(20, 20))


    # Seleziona il primo volto trovato
    if len(faces) > 0:
      Face += 1

    #cv2_imshow(image)
    #cv2.waitKey(500)


  print("\n FACES:", Face)

if __name__ == "__main__":
  main()
