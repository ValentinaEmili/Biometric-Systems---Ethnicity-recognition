{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPnAtZmjuwHJAY1VvpDEIX2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentinaEmili/Ethnicity-recognition/blob/main/Dlib/68_landmarks/demo_svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MWfJyV8K5T-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install validators\n",
        "!pip install torchvision"
      ],
      "metadata": {
        "id": "d-xgnBiYN37r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBl65NTpN6Q5",
        "outputId": "ddd4b84d-4bcb-4a4e-8b94-71a919c868e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model pre-trained on ImageNet dataset\n",
        "resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
        "# modify the fully connected layer\n",
        "resnet50.fc = torch.nn.Identity()\n",
        "resnet50.eval().to(device)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "iSbLNIXhOcu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "\n",
        "def extract_and_save_features(file_path):\n",
        "  image = ProbeImage(file_path=file_path, transform=transform)\n",
        "  image_tensor, _ = image[0]\n",
        "  image_tensor = image_tensor.to(device)\n",
        "  with torch.no_grad():\n",
        "    features = resnet50(image_tensor)\n",
        "  return features.cpu().numpy().flatten()\n",
        "  torch.cuda.empty_cache()  # Free up unused memory after each batch\n",
        "\n",
        "class ProbeImage(Dataset):\n",
        "  def __init__(self, file_path, transform=None):\n",
        "    self.transform = transform\n",
        "    self.file_path = file_path\n",
        "\n",
        "  def __getitem__(self, index=0):\n",
        "    image = Image.open(self.file_path).convert(\"RGB\")\n",
        "    image = self.transform(image).unsqueeze(0)\n",
        "    file_name = os.path.basename(self.file_path)\n",
        "    return image, file_name\n",
        "\n",
        "  def __len__(self):\n",
        "    return 1"
      ],
      "metadata": {
        "id": "bFAwGtTmOkAx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dlib\n",
        "shape_predictor_path = \"/content/drive/MyDrive/biometric_systems_project/shape_predictor_68_face_landmarks.dat\"\n",
        "detector = dlib.get_frontal_face_detector() # HOG-based detector\n",
        "predictor = dlib.shape_predictor(shape_predictor_path)"
      ],
      "metadata": {
        "id": "BPEWiihDaXCr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shape_to_normal(shape):\n",
        "  shape_normal = []\n",
        "  for i in range(0, shape.num_parts):\n",
        "    shape_normal.append((i, (shape.part(i).x, shape.part(i).y)))\n",
        "  return shape_normal\n",
        "\n",
        "def get_eyes_nose_dlib(shape):\n",
        "  nose = shape[30][1]\n",
        "  left_eye_x = (shape[36][1][0] + shape[39][1][0]) // 2\n",
        "  left_eye_y = (shape[36][1][1] + shape[39][1][1]) // 2\n",
        "  right_eyes_x = (shape[42][1][0] + shape[45][1][0]) // 2\n",
        "  right_eyes_y = (shape[42][1][1] + shape[45][1][1]) // 2\n",
        "\n",
        "  return nose, (left_eye_x, left_eye_y), (right_eyes_x, right_eyes_y)\n",
        "\n",
        "def rotate_points(shape, rotation_matrix):\n",
        "  points = []\n",
        "  for i in range(0, 68):\n",
        "    x,y = shape[i][1]\n",
        "    points.append((x, y, 1))\n",
        "  points = np.array(points)\n",
        "  rotated_points = np.dot(rotation_matrix, points.T).T\n",
        "  return np.array([(int(p[0]), int(p[1])) for p in rotated_points])\n",
        "\n",
        "def get_eyes_in_image(image, points):\n",
        "  height, width = image.shape[:2]\n",
        "  top = points[17:27][np.argmin(points[17:27, 1])]\n",
        "  bottom = points[29]\n",
        "  min_x, min_y = np.min(points[36:48, 0]), np.min(points[36:48, 1])\n",
        "  max_x, max_y = np.max(points[36:48, 0]), np.max(points[36:48, 1])\n",
        "  min_x, min_y = max(0, min_x - 10), max(top[1], min_y - 10)\n",
        "  max_x, max_y = min(width, max_x + 10), min(bottom[1], max_y + 10)\n",
        "  image = image[min_y:max_y, min_x:max_x]\n",
        "  return image\n",
        "\n",
        "def get_nose_in_image(image, points):\n",
        "  height, width = image.shape[:2]\n",
        "  top = points[36:48][np.argmin(points[36:48, 1])]\n",
        "  bottom = points[48:68][np.argmax(points[48:68, 1])]\n",
        "  min_x, min_y = np.min(points[27:36, 0]), np.min(points[27:36, 1])\n",
        "  max_x, max_y = np.max(points[27:36, 0]), np.max(points[27:36, 1])\n",
        "  min_x, min_y = max(0, min_x - 5), max(top[1], min_y - 5)\n",
        "  max_x, max_y = min(width, max_x + 5), min(bottom[1], max_y + 5)\n",
        "  image = image[min_y:max_y, min_x:max_x]\n",
        "  return image\n",
        "\n",
        "def get_mouth_in_image(image, points):\n",
        "  height, width = image.shape[:2]\n",
        "  top = points[27:36][np.argmin(points[27:36, 1])]\n",
        "  min_x, min_y = np.min(points[48:68, 0]), np.min(points[48:68, 1])\n",
        "  max_x, max_y = np.max(points[48:68, 0]), np.max(points[48:68, 1])\n",
        "  min_x, min_y = max(0, min_x - 10), max(top[1], min_y - 10)\n",
        "  max_x, max_y = min(width, max_x + 10), min(height, max_y + 10)\n",
        "  image = image[min_y:max_y, min_x:max_x]\n",
        "  return image\n",
        "\n",
        "def align_face(image, file_name):\n",
        "  output_folder = \"/content/drive/MyDrive/biometric_systems_project/trained_model\"\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  faces = detector(gray)\n",
        "  if len(faces) > 0:\n",
        "    for face in faces:\n",
        "    # Extract face bounding box coordinates\n",
        "      shape = predictor(gray, face)\n",
        "\n",
        "      # Get facial landmarks for the detected face\n",
        "      shape = shape_to_normal(shape)\n",
        "\n",
        "      # Get the nose, left eye, and right eye positions\n",
        "      nose, left_eye, right_eye = get_eyes_nose_dlib(shape)\n",
        "      delta_x = right_eye[0] - left_eye[0]\n",
        "      delta_y = right_eye[1] - left_eye[1]\n",
        "      # angle from radians to degrees\n",
        "      angle = math.atan2(delta_y, delta_x) * (180 / math.pi)\n",
        "      center_of_eyes = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)\n",
        "      rotation_matrix = cv2.getRotationMatrix2D(center_of_eyes, angle, scale=1.0)\n",
        "\n",
        "      h, w = image.shape[:2]\n",
        "      aligned_image = cv2.warpAffine(image, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR)\n",
        "      # catch features in the image\n",
        "      rotated_points = rotate_points(shape, rotation_matrix)\n",
        "      eyes_image = get_eyes_in_image(aligned_image, rotated_points)\n",
        "      nose_image = get_nose_in_image(aligned_image, rotated_points)\n",
        "      mouth_image = get_mouth_in_image(aligned_image, rotated_points)\n",
        "      if eyes_image.size == 0:\n",
        "        continue\n",
        "      if nose_image.size == 0:\n",
        "        continue\n",
        "      if mouth_image.size == 0:\n",
        "        continue\n",
        "      else:\n",
        "        eyes_image_path = os.path.join(output_folder, \"eyes.jpg\")\n",
        "        mouth_image_path = os.path.join(output_folder, \"mouth.jpg\")\n",
        "        nose_image_path = os.path.join(output_folder, \"nose.jpg\")\n",
        "        cv2.imwrite(eyes_image_path, eyes_image)\n",
        "        cv2.imwrite(mouth_image_path, mouth_image)\n",
        "        cv2.imwrite(nose_image_path, nose_image)\n",
        "        return eyes_image_path, mouth_image_path, nose_image_path"
      ],
      "metadata": {
        "id": "ZQegWfW7a_lJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "def main():\n",
        "  file_path = \"/content/drive/MyDrive/biometric_systems_project/trained_model/5_1_3_20170119154358954.jpg\"\n",
        "  folder_path = \"/content/drive/MyDrive/biometric_systems_project/trained_model\"\n",
        "  characteristics = [\"age\", \"ethnicity\", \"gender\"]\n",
        "  features = [\"eyes\", \"mouth\", \"nose\"]\n",
        "\n",
        "  image = cv2.imread(file_path)\n",
        "  eyes_image_path, nose_image_path, mouth_image_path = align_face(image, file_path)\n",
        "  for feature, image_path in zip(features, [eyes_image_path, nose_image_path, mouth_image_path]):\n",
        "    image_features = extract_and_save_features(image_path)\n",
        "    for c in characteristics:\n",
        "      feature_path = os.path.join(folder_path, c, f\"svm_model_{feature}.pkl\")\n",
        "      model = joblib.load(feature_path)\n",
        "      y_pred = model.predict([image_features])\n",
        "      print(f\"Prediction for {feature} - {c}: {y_pred[0]}\")\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "id": "nvAOISr8LL5W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}