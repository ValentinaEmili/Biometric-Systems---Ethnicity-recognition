{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzbbZMiLeD-X"
      },
      "outputs": [],
      "source": [
        "# HOG feature vectors\n",
        "%pip install gdown\n",
        "import gdown\n",
        "\n",
        "url = \"https://drive.google.com/drive/folders/1U5lsvfh8zSOfPatqXvdGHLo4j_XkEyw7?usp=share_link\"\n",
        "gdown.download_folder(url, quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet 128D vectors\n",
        "%pip install gdown\n",
        "import gdown\n",
        "\n",
        "url = \"https://drive.google.com/drive/folders/1Wjkc9I6N-InDznjsu5ETmtAecPSLQYQQ?usp=share_link\"\n",
        "gdown.download_folder(url, quiet=True)"
      ],
      "metadata": {
        "id": "a9ohDS4IeGUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGGFace vectors\n",
        "%pip install gdown\n",
        "import gdown\n",
        "\n",
        "url = \"https://drive.google.com/drive/folders/1evQY1hOVcUbg3l4mpYsMguTCqtTx78Av?usp=share_link\"\n",
        "gdown.download_folder(url, quiet=True)"
      ],
      "metadata": {
        "id": "GCzo-P5tOvUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet50 vectors\n",
        "%pip install gdown\n",
        "import gdown\n",
        "\n",
        "url = \"https://drive.google.com/drive/folders/1qxOth628bu8BsdnM_BdKjfS76gL6FtJ2?usp=share_link\"\n",
        "gdown.download_folder(url, quiet=True)"
      ],
      "metadata": {
        "id": "HwNQ4z6laFDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_recall_curve\n",
        "from collections import Counter\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE"
      ],
      "metadata": {
        "id": "RQw2Kh11cg4u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_model(X_train, y_train, kernel, class_weight):\n",
        "  scaler = StandardScaler()\n",
        "  fold_scores = []\n",
        "  # cross-validation sul training set\n",
        "  kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "  for train_idx, val_idx in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    # standardize the features\n",
        "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
        "    X_val_fold = scaler.transform(X_val_fold)\n",
        "\n",
        "    svm_model = SVC(kernel=kernel, random_state=42, class_weight=class_weight)\n",
        "\n",
        "    # train the SVM classifier\n",
        "    svm_model.fit(X_train_fold, y_train_fold)\n",
        "    y_pred = svm_model.predict(X_val_fold)\n",
        "    accuracy_score_fold = accuracy_score(y_val_fold, y_pred)\n",
        "    fold_scores.append(accuracy_score_fold)\n",
        "    print(accuracy_score_fold)\n",
        "  print(\"mean score: \", np.mean(fold_scores))\n",
        "  return np.mean(fold_scores)"
      ],
      "metadata": {
        "id": "KhC9RUbzclx8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_svm(X_train, X_test, y_train, y_test):\n",
        "  n_samples = len(X_train)\n",
        "  values_count = Counter(y_train)\n",
        "  class_weight = dict({class_idx : n_samples / count for class_idx, count in values_count.items()})\n",
        "\n",
        "  best_accuracy, best_params = 0, []\n",
        "\n",
        "  grid_params = [\n",
        "          ['rbf', class_weight],\n",
        "          #['rbf', None],\n",
        "          #['sigmoid', class_weight],\n",
        "          #['linear', class_weight]\n",
        "      ]\n",
        "\n",
        "  for params in grid_params:\n",
        "    kernel, curr_class_weight = params\n",
        "    curr_accuracy = tune_model(X_train, y_train, kernel, curr_class_weight)\n",
        "    if best_accuracy < curr_accuracy:\n",
        "      best_accuracy = curr_accuracy\n",
        "      best_params = params\n",
        "\n",
        "  # train the SVM classifier with the best parameters\n",
        "  best_kernel, best_class_weight = best_params\n",
        "  best_model = SVC(kernel=best_kernel, random_state=42, class_weight=best_class_weight)\n",
        "  best_model.fit(X_train, y_train)\n",
        "\n",
        "  # make predictions and evaluate\n",
        "  y_pred = best_model.predict(X_test)\n",
        "\n",
        "  # accuracy\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  class_report = classification_report(y_test, y_pred)\n",
        "  print(\"accuracy: \", accuracy)\n",
        "  print(class_report)"
      ],
      "metadata": {
        "id": "dJ5oj_KUcsnc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group by age\n",
        "ranges = [ [1,6], [6,13], [13,21], [21,36], [36,51], [51,76], [76,91], [91,117] ]\n",
        "avg_age = [3, 9, 17, 28, 43, 63, 83, 104]\n",
        "def dataset_and_labels(path):\n",
        "  X_train, y_train = [], []\n",
        "  for file_name in os.listdir(path):\n",
        "    file_path = os.path.join(path, file_name)\n",
        "    embedding = np.load(file_path)\n",
        "    _, age, _, _, _ = file_name.split(\"_\")\n",
        "    age = int(age)\n",
        "    X_train.append(embedding)\n",
        "    for idx, r in enumerate(ranges):\n",
        "      min_age, max_age = r\n",
        "      min_age, max_age = int(min_age), int(max_age)\n",
        "      if min_age <= age < max_age:\n",
        "        y_train.append(int(avg_age[idx]))\n",
        "  return np.array(X_train), np.array(y_train)"
      ],
      "metadata": {
        "id": "9RcWUvoUe9rg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group by gender\n",
        "\n",
        "def dataset_and_labels(path):\n",
        "  X_train, y_train = [], []\n",
        "  for file_name in os.listdir(path):\n",
        "    file_path = os.path.join(path, file_name)\n",
        "    embedding = np.load(file_path)\n",
        "    _, _, gender, _, _ = file_name.split(\"_\")\n",
        "    X_train.append(embedding)\n",
        "    y_train.append(int(gender))\n",
        "  return np.array(X_train), np.array(y_train)"
      ],
      "metadata": {
        "id": "Z1y-o9GlhsxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group by race\n",
        "\n",
        "def dataset_and_labels(path):\n",
        "  X_train, y_train = [], []\n",
        "  for file_name in os.listdir(path):\n",
        "    file_path = os.path.join(path, file_name)\n",
        "    embedding = np.load(file_path)\n",
        "    _, _, _, race, _ = file_name.split(\"_\")\n",
        "    X_train.append(embedding)\n",
        "    y_train.append(int(race))\n",
        "  return np.array(X_train), np.array(y_train)"
      ],
      "metadata": {
        "id": "8XNEhLyVhtwG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gudkza8ke6I-"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "  #folder_path = \"/content/HOG_feature_vectors\"\n",
        "  #folder_path = \"/content/ResNet_128D_vectors\"\n",
        "  #folder_path = \"/content/VGG_Face_vectors\"\n",
        "  folder_path = \"/content/ResNet50\"\n",
        "  for file_name in os.listdir(folder_path):\n",
        "\n",
        "    # zipped files in the folder biometric_systems_dataset\n",
        "    if file_name.endswith(\".zip\"):\n",
        "\n",
        "      # full path to the zip file\n",
        "      file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "      # create folder in the same path with the name of the zip file\n",
        "      extract_folder = os.path.join(folder_path, file_name.replace(\".zip\", \"\"))\n",
        "      os.makedirs(extract_folder, exist_ok=True)\n",
        "\n",
        "      # open and extract the file\n",
        "      #with zipfile.ZipFile(file_path, mode=\"r\") as zip_ref:\n",
        "      #  zip_ref.extractall(extract_folder)\n",
        "      #  os.remove(os.path.join(folder_path, file_name))\n",
        "\n",
        "  X_train_eyes, y_train_eyes = dataset_and_labels(os.path.join(folder_path, \"eyes\", \"train\"))\n",
        "  X_test_eyes, y_test_eyes = dataset_and_labels(os.path.join(folder_path, \"eyes\", \"test\"))\n",
        "  X_train_mouth, y_train_mouth = dataset_and_labels(os.path.join(folder_path, \"mouth\", \"train\"))\n",
        "  X_test_mouth, y_test_mouth = dataset_and_labels(os.path.join(folder_path, \"mouth\", \"test\"))\n",
        "  X_train_nose, y_train_nose = dataset_and_labels(os.path.join(folder_path, \"nose\", \"train\"))\n",
        "  X_test_nose, y_test_nose = dataset_and_labels(os.path.join(folder_path, \"nose\", \"test\"))\n",
        "\n",
        "  X_all = [[X_train_eyes,X_test_eyes], [X_train_mouth, X_test_mouth], [X_train_nose, X_test_nose]]\n",
        "  y_all = [[y_train_eyes, y_test_eyes], [y_train_mouth, y_test_mouth], [y_train_nose, y_test_nose]]\n",
        "\n",
        "  ros = RandomOverSampler(sampling_strategy={2: 3500, 3: 3500, 4: 3000}, random_state=42)\n",
        "  rus = RandomUnderSampler(sampling_strategy={0: 5000}, random_state=42)\n",
        "  smote = SMOTE(sampling_strategy={2: 3500, 3: 3500, 4: 3000}, random_state=42)\n",
        "\n",
        "  for idx, (X, y) in enumerate(zip(X_all, y_all)):\n",
        "    X_train, X_test = X\n",
        "    y_train, y_test = y\n",
        "    if idx == 1:\n",
        "      train_evaluate_svm(X_train, X_test, y_train, y_test)\n",
        "\n",
        "      # resampling with SMOTE\n",
        "      #X_train_resampled_smote, y_train_resampled_smote = smote.fit_resample(X_train, y_train)\n",
        "      #train_evaluate_svm(X_train_resampled_smote, X_test, y_train_resampled_smote, y_test)\n",
        "\n",
        "      # under- and oversampling\n",
        "      #X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
        "      #X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
        "      #train_evaluate_svm(X_train_resampled, X_test, y_train_resampled, y_test)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}