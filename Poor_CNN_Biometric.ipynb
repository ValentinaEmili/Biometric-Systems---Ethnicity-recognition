{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1PagBJZt2ErXvXMS-BfTiZmfcLL71xM3_","timestamp":1733492660642}],"authorship_tag":"ABX9TyOCiiIvPH8hJPHFRphh29Hl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3AuMVkGrOLz8","executionInfo":{"status":"ok","timestamp":1733490711089,"user_tz":-60,"elapsed":27780,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}},"outputId":"83cd2b62-b54f-42dd-c07b-a6504bebaac5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.6)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"]},{"output_type":"execute_result","data":{"text/plain":["['/content/Dataset/Dataset_resized.zip',\n"," '/content/Dataset/eyes_cnn.py',\n"," '/content/Dataset/mouth_cnn.py',\n"," '/content/Dataset/nose_cnn.py']"]},"metadata":{},"execution_count":1}],"source":["%pip install gdown\n","import gdown\n","\n","url = \"https://drive.google.com/drive/folders/1iYO-Kwh4RFq6mm5UNPTRO7te8T6jOA6f?usp=drive_link\"\n","gdown.download_folder(url, quiet=True)"]},{"cell_type":"code","source":["import os\n","import zipfile\n","import shutil\n","from collections import defaultdict\n","from sklearn.model_selection import train_test_split\n","\n","# Percorso della cartella Project_Biometric/Dataset\n","dataset_path = \"Dataset\"\n","\n","# Funzione per estrarre i file zip e rimuoverli\n","def extract_and_remove_zip(zip_path, extract_to):\n","    \"\"\"\n","    Estrae il contenuto di un file zip e poi elimina il file zip.\n","    Args:\n","        zip_path (str): percorso del file zip da estrarre.\n","        extract_to (str): cartella di destinazione in cui estrarre i file.\n","    \"\"\"\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_to)\n","    os.remove(zip_path)  # Rimuove il file zip dopo l'estrazione\n","    print(f\"File zip {zip_path} estratto e rimosso.\")\n","\n","# Estrai e rimuovi i file ZIP nella cartella dataset\n","zip_files = [f for f in os.listdir(dataset_path) if f.endswith('.zip')]\n","for zip_file in zip_files:\n","    zip_path = os.path.join(dataset_path, zip_file)\n","    extract_and_remove_zip(zip_path, dataset_path)\n","\n","# Funzione per analizzare il nome del file\n","# def parse_filename(filename):\n","#     parts = filename.split(\"_\")\n","#     object_type = parts[0]  # Nome oggetto (es. nose, mouth, eyes)\n","#     age = parts[1]          # Età\n","#     gender = parts[2]       # Sesso\n","#     ethnicity = parts[3]    # Etnia\n","#     return object_type, age, gender, ethnicity\n","\n","# dataset_path = \"Dataset/Dataset_resized\"\n","\n","# # Processa ogni sottocartella (ad esempio eyes, mouth, nose)\n","# for folder in os.listdir(dataset_path):\n","#     folder_path = os.path.join(dataset_path, folder)\n","\n","#     # Procedi solo se è una directory\n","#     if os.path.isdir(folder_path):\n","#         print(f\"Elaborazione della cartella: {folder}\")\n","\n","#         # Crea le sottocartelle train e test\n","#         train_folder = os.path.join(folder_path, \"train\")\n","#         test_folder = os.path.join(folder_path, \"test\")\n","#         os.makedirs(train_folder, exist_ok=True)\n","#         os.makedirs(test_folder, exist_ok=True)\n","\n","#         # Raggruppa i file in base a età ed etnia\n","#         file_groups = defaultdict(list)\n","#         files = [f for f in os.listdir(folder_path) if f.endswith(\".jpg\")]\n","\n","#         # Raggruppa per età ed etnia\n","#         for file in files:\n","#             file_path = os.path.join(folder_path, file)\n","#             try:\n","#                 object_type, age, gender, ethnicity = parse_filename(file)\n","#                 if object_type and age and gender and ethnicity:\n","#                     file_groups[(age, ethnicity)].append(file)\n","#                 else:\n","#                     print(f\"File non valido (parametri mancanti): {file}. Eliminazione...\")\n","#                     os.remove(file_path)  # Elimina file non valido\n","#             except IndexError:\n","#                 print(f\"File non conforme al formato: {file}. Eliminazione...\")\n","#                 os.remove(file_path)  # Elimina file non conforme\n","\n","#         # Suddividi i file in modo bilanciato tra train e test\n","#         train_files = []\n","#         test_files = []\n","\n","#         for group, group_files in file_groups.items():\n","#             if len(group_files) == 1:\n","#                 # Se c'è solo un file, assegnalo al training set\n","#                 train_files.extend(group_files)\n","#             else:\n","#                 # Altrimenti, suddividi il gruppo in train e test (80% train, 20% test)\n","#                 train, test = train_test_split(group_files, test_size=0.2, random_state=42)\n","#                 train_files.extend(train)\n","#                 test_files.extend(test)\n","\n","#         # Sposta i file nelle rispettive cartelle train e test\n","#         for file in train_files:\n","#             shutil.move(os.path.join(folder_path, file), os.path.join(train_folder, file))\n","\n","#         for file in test_files:\n","#             shutil.move(os.path.join(folder_path, file), os.path.join(test_folder, file))\n","\n","# # Comprime l'intera directory in un file zip\n","# zip_path = f\"{dataset_path}.zip\"\n","# print(f\"Compressione della cartella principale in: {zip_path}\")\n","# shutil.make_archive(dataset_path, 'zip', dataset_path)\n","\n","print(\"Processo completato!\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmbewJL_PSOa","executionInfo":{"status":"ok","timestamp":1733490735687,"user_tz":-60,"elapsed":24604,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}},"outputId":"edbbc74b-bdde-480a-ca1e-8acd62bc4891"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["File zip Dataset/Dataset_resized.zip estratto e rimosso.\n","Processo completato!\n"]}]},{"cell_type":"markdown","source":["**Conteggio numero immagini per ogni set**"],"metadata":{"id":"TMJOTsQy2nqT"}},{"cell_type":"code","source":["dataset_path = \"Dataset\"\n","for folder in os.listdir(dataset_path):\n","    folder_path = os.path.join(dataset_path, folder)\n","\n","    # Procedi solo se è una directory\n","    if os.path.isdir(folder_path):\n","        train_folder = os.path.join(folder_path, \"train\")\n","        test_folder = os.path.join(folder_path, \"test\")\n","\n","        train_count = len([f for f in os.listdir(train_folder) if os.path.isfile(os.path.join(train_folder, f))]) if os.path.exists(train_folder) else 0\n","        test_count = len([f for f in os.listdir(test_folder) if os.path.isfile(os.path.join(test_folder, f))]) if os.path.exists(test_folder) else 0\n","\n","        print(f\"Cartella '{folder}':\")\n","        print(f\"  Train set: {train_count} file\")\n","        print(f\"  Test set: {test_count} file\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pbmxURG1p1yz","executionInfo":{"status":"ok","timestamp":1733490736191,"user_tz":-60,"elapsed":518,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}},"outputId":"0a2f6b63-c6a6-461d-f5b9-ea66f0f2cea5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cartella 'eyes':\n","  Train set: 18255 file\n","  Test set: 4776 file\n","Cartella 'nose':\n","  Train set: 18255 file\n","  Test set: 4776 file\n","Cartella 'mouth':\n","  Train set: 18255 file\n","  Test set: 4776 file\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.optim as optim\n","from PIL import Image\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader, random_split, Dataset\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","\n","# Check if GPU is available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sjt1L2IxWeTz","executionInfo":{"status":"ok","timestamp":1733490746473,"user_tz":-60,"elapsed":10287,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}},"outputId":"50505e4b-2060-4a47-fe63-94d03ce2c368"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]}]},{"cell_type":"code","source":["# Impostare la trasformazione\n","transform_eyes = transforms.Compose([\n","    transforms.Resize((44, 266)),  # Cambia dimensione a (altezza, larghezza)\n","    transforms.ToTensor(),        # Converte l'immagine in tensor\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalizzazione\n","])\n","\n","# Transform per il naso (108x170)\n","transform_nose = transforms.Compose([\n","    transforms.Resize((170, 108)),  # Cambia dimensione a (altezza, larghezza)\n","    transforms.ToTensor(),         # Converte l'immagine in tensor\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalizzazione\n","])\n","\n","# Transform per la bocca (193x89)\n","transform_mouth = transforms.Compose([\n","    transforms.Resize((89, 193)),  # Cambia dimensione a (altezza, larghezza)\n","    transforms.ToTensor(),        # Converte l'immagine in tensor\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalizzazione\n","])\n","\n","# Dataset personalizzato\n","class EthnicityDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.images = []\n","        self.labels = []\n","\n","        # Scansione della cartella per ottenere i file\n","        for filename in os.listdir(root_dir):\n","            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Considerando immagini .jpg e .png\n","                self.images.append(filename)\n","\n","                # Estraiamo l'etnia dalla parte finale del nome del file\n","                # esempio: eyes_100_1_0_20170112213001988\n","                parts = filename.split('_')\n","                if len(parts) >= 4:\n","                    label = parts[3]  # L'etnia è il quarto elemento (indice 3)\n","                    label_map = {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4}  # Mappatura delle etnie\n","                    self.labels.append(label_map.get(label, -1))  # -1 se l'etnia non è trovata\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image_name = self.images[idx]\n","        image_path = os.path.join(self.root_dir, image_name)\n","\n","        try:\n","            image = Image.open(image_path)\n","        except Exception as e:\n","            print(f\"Errore nel caricamento dell'immagine {image_path}: {e}\")\n","            return None, None\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        label = self.labels[idx]\n","\n","        # Aggiungi un controllo se l'etichetta è corretta\n","        if label == -1:\n","            print(f\"Errore: etichetta non trovata per {image_name}\")\n","\n","        return image, label"],"metadata":{"id":"Lh0Zvz423z4-","executionInfo":{"status":"ok","timestamp":1733490746473,"user_tz":-60,"elapsed":19,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from Dataset.eyes_cnn import EyesCNN\n","from Dataset.nose_cnn import NoseCNN\n","from Dataset.mouth_cnn import MouthCNN\n","\n","eyes_net = EyesCNN()\n","nose_net = NoseCNN()\n","mouth_net = MouthCNN()\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","eyes_optimizer = optim.Adam(eyes_net.parameters(), lr=0.001)\n","nose_optimizer = optim.Adam(nose_net.parameters(), lr=0.001)\n","mouth_optimizer = optim.Adam(mouth_net.parameters(), lr=0.001)"],"metadata":{"id":"Yp9HKRYlu8DB","executionInfo":{"status":"ok","timestamp":1733490746473,"user_tz":-60,"elapsed":18,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["**EYES TRAINING VALIDATION AND TEST**"],"metadata":{"id":"5Dkmi8jNsoKr"}},{"cell_type":"code","source":["# Inizializzare il dataset\n","full_train_dataset = EthnicityDataset(root_dir=\"Dataset/eyes/train\", transform=transform_eyes)\n","test_dataset = EthnicityDataset(root_dir=\"Dataset/eyes/test\", transform=transform_eyes)\n","\n","#####################################################\n","Train_size = int(0.8 * len(full_train_dataset))\n","Val_size = len(full_train_dataset) - Train_size\n","train_dataset, val_dataset = random_split(full_train_dataset, [Train_size, Val_size])\n","\n","#####################################################\n","\n","# use these names for the data loaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n","\n","print(len(train_dataset), len(test_dataset), len(val_dataset))"],"metadata":{"id":"zpZvvRMesKS0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733490746473,"user_tz":-60,"elapsed":18,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}},"outputId":"8c0f9472-ec4f-4cc6-c7fe-74944f38ea87"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["14604 4776 3651\n"]}]},{"cell_type":"code","source":["# Initialize lists to store metrics\n","eyes_train_losses = []\n","eyes_val_losses = []\n","eyes_train_accuracies = []\n","eyes_val_accuracies = []\n","\n","\n","num_epochs = 10\n","# Training loop\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    total_batches = 0\n","\n","    # Training Phase\n","    eyes_net.train()\n","    correct = 0\n","    total = 0\n","\n","    for data in train_loader:\n","        if data is None:\n","            continue  # Se il dato è None (errore nel caricamento), lo saltiamo\n","\n","        inputs, labels = data\n","\n","        # Zero the parameter gradients\n","        eyes_optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = eyes_net(inputs)\n","        # Compute loss\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        eyes_optimizer.step()\n","\n","        running_loss += loss.item()\n","        total_batches += 1\n","\n","        # Calculate training accuracy\n","        _, y_pred = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (y_pred == labels).sum().item()\n","\n","    # Calcolare la loss e l'accuratezza media per l'epoch\n","    avg_train_loss = running_loss / total_batches\n","    train_accuracy = correct / total\n","\n","    print(f'Epoch {epoch + 1}, Average Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}')\n","\n","    # Validation Phase\n","    eyes_net.eval()\n","    val_running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for val_data in val_loader:\n","            val_inputs, val_labels = val_data\n","\n","            # Forward pass\n","            val_outputs = eyes_net(val_inputs)\n","\n","            # Compute loss\n","            val_loss = criterion(val_outputs, val_labels)\n","            val_running_loss += val_loss.item()\n","\n","            # Calculate accuracy\n","            _, val_predicted = torch.max(val_outputs.data, 1)\n","            total += val_labels.size(0)\n","            correct += (val_predicted == val_labels).sum().item()\n","\n","    # Calculate average loss for the validation epoch\n","    avg_val_loss = val_loss / val_running_loss\n","    eyes_val_losses.append(avg_val_loss)\n","\n","    # Calculate validation accuracy\n","    val_accuracy = correct / total\n","    eyes_val_accuracies.append(val_accuracy)\n","\n","\n","    print(f'Epoch {epoch + 1}, Average Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PfPc-5Wey1qF","executionInfo":{"status":"ok","timestamp":1733491206142,"user_tz":-60,"elapsed":459681,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}},"outputId":"140b0307-0a96-43c3-c0e4-578a3a3e3504"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Average Training Loss: 1.1682, Training Accuracy: 0.5498\n","Epoch 1, Average Validation Loss: 0.0248, Validation Accuracy: 0.6018\n","Epoch 2, Average Training Loss: 1.0139, Training Accuracy: 0.6259\n","Epoch 2, Average Validation Loss: 0.0080, Validation Accuracy: 0.6343\n","Epoch 3, Average Training Loss: 0.9696, Training Accuracy: 0.6435\n","Epoch 3, Average Validation Loss: 0.0260, Validation Accuracy: 0.6335\n","Epoch 4, Average Training Loss: 0.9408, Training Accuracy: 0.6553\n","Epoch 4, Average Validation Loss: 0.0136, Validation Accuracy: 0.6431\n","Epoch 5, Average Training Loss: 0.9213, Training Accuracy: 0.6602\n","Epoch 5, Average Validation Loss: 0.0082, Validation Accuracy: 0.6601\n","Epoch 6, Average Training Loss: 0.9031, Training Accuracy: 0.6736\n","Epoch 6, Average Validation Loss: 0.0157, Validation Accuracy: 0.6486\n","Epoch 7, Average Training Loss: 0.8901, Training Accuracy: 0.6775\n","Epoch 7, Average Validation Loss: 0.0066, Validation Accuracy: 0.6483\n","Epoch 8, Average Training Loss: 0.8724, Training Accuracy: 0.6836\n","Epoch 8, Average Validation Loss: 0.0096, Validation Accuracy: 0.6376\n","Epoch 9, Average Training Loss: 0.8493, Training Accuracy: 0.6904\n","Epoch 9, Average Validation Loss: 0.0197, Validation Accuracy: 0.6524\n","Epoch 10, Average Training Loss: 0.8370, Training Accuracy: 0.6955\n","Epoch 10, Average Validation Loss: 0.0036, Validation Accuracy: 0.6686\n","Finished Training\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"t8L59rANy1aW"}},{"cell_type":"code","source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        images, labels = data\n","        outputs = eyes_net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy on the test images: {100 * correct / total:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bu9J9QOS7_hJ","executionInfo":{"status":"ok","timestamp":1733491216567,"user_tz":-60,"elapsed":10437,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}},"outputId":"8dc8d0be-dfff-4886-ab01-63c2721ee4b4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on the test images: 65.05%\n"]}]},{"cell_type":"markdown","source":["**NOSE TRAINING VALIDATION AND TEST**"],"metadata":{"id":"ReSQIrMH85RS"}},{"cell_type":"code","source":["# Inizializzare il dataset\n","full_train_dataset = EthnicityDataset(root_dir=\"Dataset/nose/train\", transform=transform_nose)\n","test_dataset = EthnicityDataset(root_dir=\"Dataset/nose/test\", transform=transform_nose)\n","\n","#####################################################\n","Train_size = int(0.8 * len(full_train_dataset))\n","Val_size = len(full_train_dataset) - Train_size\n","train_dataset, val_dataset = random_split(full_train_dataset, [Train_size, Val_size])\n","\n","#####################################################\n","\n","# use these names for the data loaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n","\n","print(len(train_dataset), len(test_dataset), len(val_dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Po66Mi4J8csA","executionInfo":{"status":"ok","timestamp":1733491216568,"user_tz":-60,"elapsed":15,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}},"outputId":"9a5be1bd-921f-456a-8c25-627f0def68c1"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["14604 4776 3651\n"]}]},{"cell_type":"code","source":["# Initialize lists to store metrics\n","nose_train_losses = []\n","nose_val_losses = []\n","nose_train_accuracies = []\n","nose_val_accuracies = []\n","\n","\n","num_epochs = 10\n","# Training loop\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    total_batches = 0\n","\n","    # Training Phase\n","    nose_net.train()\n","    correct = 0\n","    total = 0\n","\n","    for data in train_loader:\n","        if data is None:\n","            continue  # Se il dato è None (errore nel caricamento), lo saltiamo\n","\n","        inputs, labels = data\n","\n","        # Zero the parameter gradients\n","        nose_optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = nose_net(inputs)\n","        # Compute loss\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        nose_optimizer.step()\n","\n","        running_loss += loss.item()\n","        total_batches += 1\n","\n","        # Calculate training accuracy\n","        _, y_pred = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (y_pred == labels).sum().item()\n","\n","    # Calcolare la loss e l'accuratezza media per l'epoch\n","    avg_train_loss = running_loss / total_batches\n","    train_accuracy = correct / total\n","\n","    print(f'Epoch {epoch + 1}, Average Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}')\n","\n","    # Validation Phase\n","    nose_net.eval()\n","    val_running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for val_data in val_loader:\n","            val_inputs, val_labels = val_data\n","\n","            # Forward pass\n","            val_outputs = nose_net(val_inputs)\n","\n","            # Compute loss\n","            val_loss = criterion(val_outputs, val_labels)\n","            val_running_loss += val_loss.item()\n","\n","            # Calculate accuracy\n","            _, val_predicted = torch.max(val_outputs.data, 1)\n","            total += val_labels.size(0)\n","            correct += (val_predicted == val_labels).sum().item()\n","\n","    # Calculate average loss for the validation epoch\n","    avg_val_loss = val_loss / val_running_loss\n","    nose_val_losses.append(avg_val_loss)\n","\n","    # Calculate validation accuracy\n","    val_accuracy = correct / total\n","    nose_val_accuracies.append(val_accuracy)\n","\n","\n","    print(f'Epoch {epoch + 1}, Average Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cmZyd-UU8-0p","executionInfo":{"status":"ok","timestamp":1733491978469,"user_tz":-60,"elapsed":761912,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}},"outputId":"40365151-0445-44ee-9b09-ba1be582eb0c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Average Training Loss: 1.2725, Training Accuracy: 0.5008\n","Epoch 1, Average Validation Loss: 0.0166, Validation Accuracy: 0.5314\n","Epoch 2, Average Training Loss: 1.1654, Training Accuracy: 0.5522\n","Epoch 2, Average Validation Loss: 0.0256, Validation Accuracy: 0.5681\n","Epoch 3, Average Training Loss: 1.1187, Training Accuracy: 0.5737\n","Epoch 3, Average Validation Loss: 0.0121, Validation Accuracy: 0.5475\n","Epoch 4, Average Training Loss: 1.0916, Training Accuracy: 0.5864\n","Epoch 4, Average Validation Loss: 0.0187, Validation Accuracy: 0.5793\n","Epoch 5, Average Training Loss: 1.0678, Training Accuracy: 0.5972\n","Epoch 5, Average Validation Loss: 0.0061, Validation Accuracy: 0.5763\n","Epoch 6, Average Training Loss: 1.0629, Training Accuracy: 0.6005\n","Epoch 6, Average Validation Loss: 0.0303, Validation Accuracy: 0.5982\n","Epoch 7, Average Training Loss: 1.0366, Training Accuracy: 0.6118\n","Epoch 7, Average Validation Loss: 0.0267, Validation Accuracy: 0.5812\n","Epoch 8, Average Training Loss: 1.0203, Training Accuracy: 0.6159\n","Epoch 8, Average Validation Loss: 0.0206, Validation Accuracy: 0.5965\n","Epoch 9, Average Training Loss: 1.0108, Training Accuracy: 0.6255\n","Epoch 9, Average Validation Loss: 0.0245, Validation Accuracy: 0.6028\n","Epoch 10, Average Training Loss: 0.9907, Training Accuracy: 0.6311\n","Epoch 10, Average Validation Loss: 0.0239, Validation Accuracy: 0.6133\n","Finished Training\n"]}]},{"cell_type":"code","source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        images, labels = data\n","        outputs = nose_net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy on the test images: {100 * correct / total:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-d2jiCq9gIz","executionInfo":{"status":"ok","timestamp":1733491994434,"user_tz":-60,"elapsed":15978,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}},"outputId":"c1a45aa4-7503-454b-86d9-c6dd3431ea5f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on the test images: 59.86%\n"]}]},{"cell_type":"markdown","source":["**MOUTH TRAINING VALIDATION AND TEST**"],"metadata":{"id":"4USmhOOI9m8D"}},{"cell_type":"code","source":["# Inizializzare il dataset\n","full_train_dataset = EthnicityDataset(root_dir=\"Dataset/mouth/train\", transform=transform_mouth)\n","test_dataset = EthnicityDataset(root_dir=\"Dataset/mouth/test\", transform=transform_mouth)\n","\n","#####################################################\n","Train_size = int(0.8 * len(full_train_dataset))\n","Val_size = len(full_train_dataset) - Train_size\n","train_dataset, val_dataset = random_split(full_train_dataset, [Train_size, Val_size])\n","\n","#####################################################\n","\n","# use these names for the data loaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n","\n","print(len(train_dataset), len(test_dataset), len(val_dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufqXefFA9t56","executionInfo":{"status":"ok","timestamp":1733491994436,"user_tz":-60,"elapsed":15,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}},"outputId":"b4495939-e1eb-459a-cde2-b5bdc8828b95"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["14604 4776 3651\n"]}]},{"cell_type":"code","source":["# Initialize lists to store metrics\n","mouth_train_losses = []\n","mouth_val_losses = []\n","mouth_train_accuracies = []\n","mouth_val_accuracies = []\n","\n","\n","num_epochs = 10\n","# Training loop\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    total_batches = 0\n","\n","    # Training Phase\n","    mouth_net.train()\n","    correct = 0\n","    total = 0\n","\n","    for data in train_loader:\n","        if data is None:\n","            continue  # Se il dato è None (errore nel caricamento), lo saltiamo\n","\n","        inputs, labels = data\n","\n","        # Zero the parameter gradients\n","        mouth_optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = mouth_net(inputs)\n","        # Compute loss\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        mouth_optimizer.step()\n","\n","        running_loss += loss.item()\n","        total_batches += 1\n","\n","        # Calculate training accuracy\n","        _, y_pred = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (y_pred == labels).sum().item()\n","\n","    # Calcolare la loss e l'accuratezza media per l'epoch\n","    avg_train_loss = running_loss / total_batches\n","    train_accuracy = correct / total\n","\n","    print(f'Epoch {epoch + 1}, Average Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}')\n","\n","    # Validation Phase\n","    mouth_net.eval()\n","    val_running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for val_data in val_loader:\n","            val_inputs, val_labels = val_data\n","\n","            # Forward pass\n","            val_outputs = mouth_net(val_inputs)\n","\n","            # Compute loss\n","            val_loss = criterion(val_outputs, val_labels)\n","            val_running_loss += val_loss.item()\n","\n","            # Calculate accuracy\n","            _, val_predicted = torch.max(val_outputs.data, 1)\n","            total += val_labels.size(0)\n","            correct += (val_predicted == val_labels).sum().item()\n","\n","    # Calculate average loss for the validation epoch\n","    avg_val_loss = val_loss / val_running_loss\n","    mouth_val_losses.append(avg_val_loss)\n","\n","    # Calculate validation accuracy\n","    val_accuracy = correct / total\n","    mouth_val_accuracies.append(val_accuracy)\n","\n","\n","    print(f'Epoch {epoch + 1}, Average Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-55Okk969ug2","executionInfo":{"status":"ok","timestamp":1733492607782,"user_tz":-60,"elapsed":613357,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}},"outputId":"c34f21a5-edf8-454a-e66b-77682de20fbf"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Average Training Loss: 1.1753, Training Accuracy: 0.5503\n","Epoch 1, Average Validation Loss: 0.0178, Validation Accuracy: 0.5420\n","Epoch 2, Average Training Loss: 1.1076, Training Accuracy: 0.5813\n","Epoch 2, Average Validation Loss: 0.0125, Validation Accuracy: 0.5664\n","Epoch 3, Average Training Loss: 1.0797, Training Accuracy: 0.5921\n","Epoch 3, Average Validation Loss: 0.0181, Validation Accuracy: 0.5776\n","Epoch 4, Average Training Loss: 1.0590, Training Accuracy: 0.6011\n","Epoch 4, Average Validation Loss: 0.0231, Validation Accuracy: 0.5867\n","Epoch 5, Average Training Loss: 1.0399, Training Accuracy: 0.6070\n","Epoch 5, Average Validation Loss: 0.0212, Validation Accuracy: 0.5774\n","Epoch 6, Average Training Loss: 1.0168, Training Accuracy: 0.6175\n","Epoch 6, Average Validation Loss: 0.0226, Validation Accuracy: 0.5831\n","Epoch 7, Average Training Loss: 0.9984, Training Accuracy: 0.6277\n","Epoch 7, Average Validation Loss: 0.0176, Validation Accuracy: 0.5889\n","Epoch 8, Average Training Loss: 0.9910, Training Accuracy: 0.6263\n","Epoch 8, Average Validation Loss: 0.0273, Validation Accuracy: 0.5831\n","Epoch 9, Average Training Loss: 0.9765, Training Accuracy: 0.6352\n","Epoch 9, Average Validation Loss: 0.0270, Validation Accuracy: 0.5845\n","Epoch 10, Average Training Loss: 0.9613, Training Accuracy: 0.6413\n","Epoch 10, Average Validation Loss: 0.0188, Validation Accuracy: 0.5881\n","Finished Training\n"]}]},{"cell_type":"code","source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        images, labels = data\n","        outputs = mouth_net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy on the test images: {100 * correct / total:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kV3v71eK9u-U","executionInfo":{"status":"ok","timestamp":1733492620957,"user_tz":-60,"elapsed":13187,"user":{"displayName":"adriano semerano","userId":"17260051318493691202"}},"outputId":"31e827df-4c4a-4d4b-9e2d-07714fd1d76d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on the test images: 60.03%\n"]}]}]}